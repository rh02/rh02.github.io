<!doctype html>
<html lang="zh-CN">
<head>

     
      

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.51" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Hadoop2.x 完全分布式安装&amp;部署 | 申恒恒的博客</title>
    <meta property="og:title" content="Hadoop2.x 完全分布式安装&amp;部署 - 申恒恒的博客">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content="2018-04-14T00:00:00&#43;08:00">
        
        
    <meta property="article:modified_time" content="2018-04-14T00:00:00&#43;08:00">
        
    <meta name="Keywords" content="golang,go语言,go语言笔记,申恒恒,java,android,大数据,Hadoop,Spark,Storm,Streaming,强化学习,计算机视觉,机器学习,深度学习,容器技术,kubernetes,Docker,博客,项目管理,python,软件架构,公众号,小程序">
    <meta name="description" content="Hadoop2.x 完全分布式安装&amp;部署">
        <meta name="author" content="申恒恒">
        
    <meta property="og:url" content="http://shenheng.xyz/posts/2018-04-14-hadoop2-setup-2/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
        <link rel="stylesheet" href="/css/prism.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <script async type="text/javascript" src="/js/jquery-3.3.1.min.js"></script>

    
        
        
            <script async src="https://www.googletagmanager.com/gtag/js?id=UA-92073513-2"></script>
            <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-92073513-2');
        </script>
        

    

    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
        (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-9076793735164845",
            enable_page_level_ads: true
        });
    </script>
    
    


    
    
</head>

<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="http://shenheng.xyz">
                        申恒恒的博客
                    </a>
                
                <p class="description">专注于Python、Java、Go语言(golang)、机器学习、深度学习、大数据、云计算、容器技术、软件架构</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="http://shenheng.xyz">首页</a>
                    
                    <a  href="http://shenheng.xyz/learning/" title="笔记">笔记</a>
                    
                    <a  href="http://shenheng.xyz/archives/" title="归档">归档</a>
                    
                    <a  href="http://shenheng.xyz/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    <article class="post">
                        <header>
                            <h1 class="post-title">Hadoop2.x 完全分布式安装&amp;部署</h1>
                        </header>
                        <date class="post-meta meta-date">
                            2018年4月14日
                        </date>
                        
                        <div class="post-meta meta-category">
                            |
                            
                                <a href="http://shenheng.xyz/categories/hadoop">hadoop</a>
                            
                                <a href="http://shenheng.xyz/categories/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B">安装教程</a>
                            
                        </div>
                        
                        
                        <div class="post-meta">
                            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span> 阅读</span></span>
                        </div>
                        
                        
                            <aside id="toc" class="dismissed">
                                <span class="toc-title">目录 <a href="#" class="toc-dismiss"></a></span>
                                <nav id="TableOfContents">
<ul>
<li><a href="#实验环境准备">实验环境准备</a></li>
<li><a href="#安装-hadoop-并设置其所需的环境变量">安装 hadoop 并设置其所需的环境变量</a>
<ul>
<li><a href="#检查-java">检查 java</a></li>
<li><a href="#创建密钥并传输配置文件">创建密钥并传输配置文件</a></li>
</ul></li>
<li><a href="#创建运行-hadoop-进程的用户和相关目录">创建运行 Hadoop 进程的用户和相关目录</a>
<ul>
<li><a href="#创建用户和组">创建用户和组：</a></li>
<li><a href="#创建数据和日志目录">创建数据和日志目录</a></li>
</ul></li>
<li><a href="#配置-hadoop">配置 Hadoop</a>
<ul>
<li><a href="#etc-hadoop-core-site-xml">etc/hadoop/core-site.xml</a></li>
<li><a href="#etc-hadoop-hdfs-site-xml">etc/hadoop/hdfs-site.xml</a></li>
<li><a href="#etc-hadoop-mapred-site-xml">etc/hadoop/mapred-site.xml</a></li>
<li><a href="#etc-hadoop-yarn-site-xml">etc/hadoop/yarn-site.xml</a></li>
<li><a href="#etc-hadoop-hadoop-env-sh和etc-hadoop-yarn-env-sh">etc/hadoop/hadoop-env.sh和etc/hadoop/yarn-env.sh</a></li>
<li><a href="#slaves文件">slaves文件</a></li>
</ul></li>
<li><a href="#配置各slave节点">配置各slave节点</a></li>
<li><a href="#格式化hdfs">格式化HDFS</a></li>
<li><a href="#启动hadoop集群">启动hadoop集群</a>
<ul>
<li><a href="#分别启动">分别启动</a></li>
<li><a href="#在-master-节点控制整个集群">在 master 节点控制整个集群</a></li>
</ul></li>
<li><a href="#验证">验证</a></li>
</ul>
</nav>
                            </aside>
                        
                        
                        <div class="post-content">
                            

<p>目前主要有以下四种部署方案：</p>

<ul>
<li>伪分布式</li>
<li>真正分布式</li>
<li>HA分布式</li>
<li>HA分布式+</li>
</ul>

<p>本次教程主要说明 Hadoop 完全分布式方案安装与部署，教程相比较来说比较成熟，已经测试很多次！</p>

<!-- Hadoop分布式集群部署方案 -->

<h1 id="实验环境准备">实验环境准备</h1>

<ul>
<li>4×CentOS7.1虚拟机

<ul>
<li>1×master  x86_64位系统，2G RAM，40GB硬盘容量</li>
<li>3×slave   x86_64位系统，1.5G RAM，40GB硬盘容量</li>
</ul></li>
<li>IP地址分配</li>
</ul>

<table>
<thead>
<tr>
<th>IP地址</th>
<th>主机名</th>
</tr>
</thead>

<tbody>
<tr>
<td>192.168.59.<sup>150</sup>&frasl;<sub>24</sub></td>
<td>master</td>
</tr>

<tr>
<td>192.168.59.<sup>154</sup>&frasl;<sub>24</sub></td>
<td>dn1</td>
</tr>

<tr>
<td>192.168.59.<sup>155</sup>&frasl;<sub>24</sub></td>
<td>dn2</td>
</tr>

<tr>
<td>192.168.59.<sup>156</sup>&frasl;<sub>24</sub></td>
<td>dn3</td>
</tr>
</tbody>
</table>

<h1 id="安装-hadoop-并设置其所需的环境变量">安装 hadoop 并设置其所需的环境变量</h1>

<p>以下都是针对所有的机器设定的，包括第3节.</p>

<p>##首先关闭防火墙和SeLinux</p>

<ul>
<li>清除iptables规则</li>
</ul>

<pre><code class="language-bash">iptables -F
iptables -X
iptables –Z
chkconfig iptables off # 永久关闭
systemctl stop firewalld
systemctl disable firewalld #开机禁用
setenforce 0
</code></pre>

<h2 id="检查-java">检查 java</h2>

<p>然后检查是否安装上 <code>java1.7.0+</code> ,若未安装，在所有机器上执行下面步骤</p>

<pre><code class="language-bash">yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel –y
</code></pre>

<p>然后检查 java 的版本号</p>

<pre><code class="language-bash">[root@node ~]# java -version
openjdk version &quot;1.8.0_161&quot;
OpenJDK Runtime Environment (build 1.8.0_161-b14)
OpenJDK 64-Bit Server VM (build 25.161-b14, mixed mode)
</code></pre>

<p>并且将 java 写进环境变量中，这里环境变量有多种方式，可以写进 <code>/etc/profile</code> 文件中，但是一般地，运维人员喜欢单独存放在 <code>/etc/profile.d/</code> 文件夹下，新建一个 <code>java.sh</code> .
这里在 <code>/etc/profile.d/</code> 下新建一个文件 <code>java.sh</code>，并且内容如下：</p>

<pre><code class="language-sh">export JAVA_HOME=/usr
</code></pre>

<p>然后将配置文件通过 scp 命令发送到 slaves。</p>

<pre><code class="language-bash">[root@master~]# for i in {dn1,dn2,dn3};do scp /etc/profile.d/java.sh  root@${i}:/etc/profile.d/ ; done
</code></pre>

<blockquote>
<p>下面是我从搭建的ftp服务器中获取的安装包（这步可以省略）</p>

<pre><code class="language-bash">[root@node ~]# lftps
口令: 
lftp shine@192.168.59.1:~&gt; cd 7.x86_64/hadoop2/
lftp shine@192.168.59.1:/7.x86_64/hadoop2&gt; get hadoop-2.6.2.tar.gz 
195515434 bytes transferred in 5 seconds (34.87M/s)
lftp shine@192.168.59.1:/7.x86_64/hadoop2&gt; bye
</code></pre>
</blockquote>

<p>然后解压 hadoop2.6.x 安装包至指定目录下,</p>

<pre><code class="language-bash">[root@node ~]# mkdir -pv /bdapps/
[root@node ~]# tar xf hadoop-2.6.2.tar.gz -C /bdapps/
[root@node ~]# ln -sv /bdapps/hadoop-2.6.2 /bdapps/hadoop
&quot;/bdapps/hadoop&quot; -&gt; &quot;/bdapps/hadoop-2.6.2&quot;
</code></pre>

<p>接下来需要单独编辑环境配置文件 <code>/etc/profile.d/hadoop.sh</code>，定义类似如下环境环境变量，设定 Hadoop 的运行环境。</p>

<pre><code class="language-bash">export HADOOP_PREFIX=&quot;/bdapps/hadoop&quot;
export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin
export HADOOP_COMMON_HOME=${HADOOP_PREFIX}
export HADOOP_HDFS_HOME=${HADOOP_PREFIX}
export HADOOP_MAPRED_HOME=${HADOOP_PREFIX}
export HADOOP_YARN_HOME=${HADOOP_PREFIX}
</code></pre>

<p>同样通过 scp 发送到 slaves。</p>

<pre><code class="language-sh">[root@master ~]# for i in {dn1,dn2,dn3};do scp /etc/profile.d/hadoop.sh  root@${i}:/etc/profile.d/ ; done
</code></pre>

<h2 id="创建密钥并传输配置文件">创建密钥并传输配置文件</h2>

<p>[ <strong>提前做</strong> ] 为了方便起见，建议利用密钥来连接各个slave，方便后面的文件传输。</p>

<pre><code class="language-bash">[root@master ~]# ssh-keygen -t rsa -b 4096 -P ''

Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa): 
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
b6:3d:02:8f:89:7b:63:26:cf:bf:38:e2:0b:39:2c:59 root@master
The key's randomart image is:
+--[ RSA 4096]----+
|                 |
|                 |
|                 |
|                 |
|  E   . S         |
| + . . * o           |
|o = . o + o         |
| . ooo*. . .          |
|   .+O++o.        |
+-------------------------+
</code></pre>

<pre><code class="language-bash">[root@master ~]# for i in {dn1,dn2,dn3};do ssh-copy-id -i .ssh/id_rsa.pub root@${i}; done
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@dn1's password: 
Number of key(s) added: 1
Now try logging into the machine, with:   &quot;ssh 'root@dn1'&quot;
and check to make sure that only the key(s) you wanted were added.

/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@dn2's password: 
Number of key(s) added: 1

Now try logging into the machine, with:   &quot;ssh 'root@dn2'&quot;
and check to make sure that only the key(s) you wanted were added.

/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@dn3's password: 
Number of key(s) added: 1
Now try logging into the machine, with:   &quot;ssh 'root@dn3'&quot;
and check to make sure that only the key(s) you wanted were added.
</code></pre>

<pre><code class="language-bash">[root@master ~]# for i in {dn1,dn2,dn3};do scp /etc/hosts root@${i}:/etc/ ; done
hosts                                      100%  266     0.3KB/s   00:00    
hosts                                      100%  266     0.3KB/s   00:00    
hosts                                      100%  266     0.3KB/s   00:00
</code></pre>

<pre><code class="language-bash">[root@master ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.69.150	master
192.168.59.154	dn1
192.168.59.155	dn2
192.168.59.156	dn3 
</code></pre>

<h1 id="创建运行-hadoop-进程的用户和相关目录">创建运行 Hadoop 进程的用户和相关目录</h1>

<p>每台主机都要做。</p>

<h2 id="创建用户和组">创建用户和组：</h2>

<p>出于安全等目的，通常需要用特定的用户来运行 hadoop 不同的守护进程，例如，以 hadoop为组，分别用三个用户 yarn、hdfs 和 mapred 来运行相应的进程。</p>

<pre><code class="language-bash">[root@node ~]# groupadd hadoop
[root@node ~]# useradd -g hadoop hdfs
[root@node ~]# useradd -g hadoop yarn
[root@node ~]# useradd -g hadoop mapred
[root@node ~]# groupadd hadoop
[root@node ~]# for user in yarn hdfs mapred;do useradd -g hadoop ${user} &amp;&amp; echo 'hadoop' | passwd --stdin ${user};done
</code></pre>

<h2 id="创建数据和日志目录">创建数据和日志目录</h2>

<p>Hadoop 需要不同权限的数据和日志目录，这里以/data/hadoop/hdfs 为 hdfs 数据存储目录。</p>

<pre><code class="language-bash">[root@node ~]# mkdir -pv /data/hadoop/hdfs/{nn,snn,dn}
[root@node ~]# chown -R hdfs:hadoop /data/hadoop/hdfs/
[root@node ~]# mkdir -p /var/log/hadoop/yarn
[root@node ~]# chown -R yarn:hadoop /var/log/hadoop/yarn/
</code></pre>

<p>而后在hadoop的安装目录中创建log目录。并且修改hadoop所有文件的属主和属性。</p>

<pre><code class="language-bash">[root@node ~]# cd /bdapps/hadoop/
[root@master hadoop]# mkdir logs
[root@master hadoop]# chown g+w logs/ 
[root@master hadoop]# chmod g+w logs/
[root@master hadoop]# chown -R yarn:hadoop ./*
</code></pre>

<h1 id="配置-hadoop">配置 Hadoop</h1>

<h2 id="etc-hadoop-core-site-xml">etc/hadoop/core-site.xml</h2>

<p>core-site.xml 文件包含了 NameNode 主机地址以及其监听 RPC 端口等信息，对于伪分布式模型的安装来说，其主机地址为 master。NameNode 默认使用的 RPC 端口为 8020。其简要的配置内容如下所示。</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
	&lt;name&gt;fs.defaultFS&lt;/name&gt;
 	&lt;value&gt;hdfs://master:8020&lt;/value&gt;
	&lt;final&gt;true&lt;/final&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h2 id="etc-hadoop-hdfs-site-xml">etc/hadoop/hdfs-site.xml</h2>

<p>hdfs-site.xml 主要用于配置 HDFS 相关的属性，例如复制因子（即数据块的副本数）、NN 和DN 用于存储数据的目录等。数据块的副本数为所需要冗余的数值2，而 NN 和DN 用于存储的数据的目录为前面的步骤中专门为其创建的路径。另外，前面的步骤中也为SNN 创建了相关的目录，这里也一并配置其为启用状态。</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
	&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
	&lt;value&gt;file:///data/hadoop/hdfs/nn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;file:///data/hadoop/hdfs/dn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
	&lt;name&gt;fs.checkpoint.dir&lt;/name&gt;
	&lt;value&gt;file:///data/hadoop/hdfs/snn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
	&lt;name&gt;fs.checkpoint.edits.dir&lt;/name&gt;
	&lt;value&gt;file:///data/hadoop/hdfs/snn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>注意，如果需要其它用户对 hdfs 有写入权限，还需要在 hdfs-site.xml 添加一项属性定义。</p>

<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;dfs.permissions&lt;/name&gt;
	&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
</code></pre>

<h2 id="etc-hadoop-mapred-site-xml">etc/hadoop/mapred-site.xml</h2>

<p>mapred-site.xml 文件用于配置集群的 MapReduce framework，此处应该指定使用 yarn，另外的可用值还有local和classic 。 mapred-site.xml默认不存在，但有模块文件mapred-site.xml.template.只需要将其复制 mapred-site.xml 即可。</p>

<pre><code class="language-bash">[root@node ~]# cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml
</code></pre>

<p>其配置示例如下面的内容。</p>

<pre><code class="language-xml">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
		&lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h2 id="etc-hadoop-yarn-site-xml">etc/hadoop/yarn-site.xml</h2>

<p>yarn-site.xml 用于配置 YARN 进程及 YARN 的相关属性。首先需要指定 ResourceManager 守护进程的主机和监听的端口，对于分布式模型来讲，其主机为 master，默认的端口为8032；其次需要指定 ResourceManager 使用的 scheduler，以及 NodeManager 的辅助服务。
一个简要的配置示例如下所示。</p>

<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
        &lt;value&gt;master:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
        &lt;value&gt;master:8030&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
        &lt;value&gt;master:8031&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
        &lt;value&gt;master:8033&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
        &lt;value&gt;master:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.auxservices.mapreduce_shuffle.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<h2 id="etc-hadoop-hadoop-env-sh和etc-hadoop-yarn-env-sh">etc/hadoop/hadoop-env.sh和etc/hadoop/yarn-env.sh</h2>

<p>Hadoop 的各守护进程依赖于 JAVA_HOME 环境变量，如果有类似于前面步骤中通过 /etc/profile.d/java.sh 全局配置定义的JAVA_HOME 变量即可正常使用。不过，如果想为Hadoop 定义依赖到的特定 JAVA 环境，也可以编辑这两个脚本文件，为其 JAVA_HOME 取消注释并配置合适的值即可。此外，Hadoop 大多数守护进程默认使用的堆大小为 1GB，但现实应用中，可能需要对其各类进程的堆内存大小做出调整，这只需要编辑此两者文件中的相关环境变量值即可，
比如：</p>

<pre><code>HADOOP_HEAPSIZE
HADOOP_JOB_HISTORY_HEAPSIZE
JAVA_HEAP_SIZE 
YARN_HEAP_SIZE
</code></pre>

<p>在这里就不做出修改了</p>

<h2 id="slaves文件">slaves文件</h2>

<p>slaves 文件存储于了当前集群的所有 slave 节点的列表，对于分布式模型，其文件内容应该为所有slave的主机名，这也的确是这个文件的默认值。因此，伪分布式模型中，此文件的内容保持默认即可。</p>

<pre><code class="language-bash">dn1
dn2
dn3
</code></pre>

<h1 id="配置各slave节点">配置各slave节点</h1>

<p>slave 节点的配置与 master 节点相同，只是启动的服务不同，因此，在各 slave 节点创建所需的用户、组和目录、设置好权限并安装 hadoop 之后后，将 master 节点的各配置文件直接复制到各 slave 节点 hadoop 配置文件目录，再为其设置好各环境变量即可。所有 slave 节点的安装配置过程均相同。</p>

<p>(1) 以下步骤在各 slave 节点操作:</p>

<p><strong>设置好 JAVA_HOME 变量</strong>，而后解压安装包至指定目录下</p>

<pre><code class="language-bash">mkdir -pv /bdapps/
tar xf hadoop-2.6.2.tar.gz -C /bdapps/
ln -sv /bdapps/hadoop-2.6.2 /bdapps/hadoop
</code></pre>

<p>编辑环境配置文件/etc/profile.d/hadoop.sh，定义类似如下环境环境变量，设定 Hadoop 的运行环境。</p>

<pre><code class="language-bash">export HADOOP_PREFIX=&quot;/bdapps/hadoop&quot;
export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin
export HADOOP_COMMON_HOME=${HADOOP_PREFIX}
export HADOOP_HDFS_HOME=${HADOOP_PREFIX}
export HADOOP_MAPRED_HOME=${HADOOP_PREFIX}
export HADOOP_YARN_HOME=${HADOOP_PREFIX}
</code></pre>

<p><strong>创建用户和组</strong>, 出于安全等目的，通常需要用特定的用户来运行 hadoop 不同的守护进程，例如，以 hadoop为组，分别用三个用户 yarn、hdfs 和 mapred 来运行相应的进程。</p>

<pre><code class="language-bash">groupadd hadoop
for user in hdfs yarn mapred; do useradd -g hadoop $user &amp;&amp; echo 'YOUR_PASSWORD' |  passwd --stdin $user; done
</code></pre>

<p><strong>创建数据和日志目录</strong> , Hadoop 需要不同权限的数据和日志目录，这里以/data/hadoop/hdfs 为 hdfs 数据存储目录。一般来说，从节点只用得到 dn 子目录。</p>

<pre><code class="language-bash">mkdir -pv /data/hadoop/hdfs/{nn,snn,dn}
chown -R hdfs:hadoop /data/hadoop/hdfs/
mkdir -p /var/log/hadoop/yarn
chown yarn:hadoop /var/log/hadoop/yarn
</code></pre>

<p>而后，在 hadoop 的安装目录中创建 logs 目录，并修改 hadoop 所有文件的属主和属组。</p>

<pre><code class="language-bash">cd /bdapps/hadoop/
mkdir logs
chmod g+w logs
chown -R yarn:hadoop ./*
</code></pre>

<p>(2) 下面的步骤在 master 节点操作</p>

<pre><code class="language-bash">[yarn@master ~]$ ssh-keygen -t rsa -P ''
[yarn@master ~]$ for i in 1 2 3; do ssh-copy-id -i .ssh/id_rsa.pub yarn@dn${i};done
</code></pre>

<pre><code class="language-bash">[hdfs@master ~]$ ssh-keygen -t rsa -P ''
[hdfs@master ~]$ for i in 1 2 3; do ssh-copy-id -i .ssh/id_rsa.pub hdfs@dn${i};done
</code></pre>

<pre><code class="language-bash">[mapred@master ~]$ ssh-keygen -t rsa -P ''
[mapred@master ~]$ for i in 1 2 3; do ssh-copy-id -i .ssh/id_rsa.pub mapred@dn${i};done
</code></pre>

<p>复制配置文件至各 slave 节点。</p>

<pre><code class="language-bash">for slave in node2 node3 node4; do scp /bdapps/hadoop/etc/hadoop/{core-site.xml,hdfs-site.xml,yarn-site.xml,mapred-site.xml}  ${slave}:/bdapps/hadoop/etc/hadoop/; done
</code></pre>

<h1 id="格式化hdfs">格式化HDFS</h1>

<p>与伪分布式模式相同，在 HDFS 集群的 NN 启动之前需要先初始化其用于存储数据的目录。如果 hdfs-site.xml 中 dfs.namenode.name.dir 属性指定的目录不存在，格式化命令会自动创建之；如果事先存在，请确保其权限设置正确，此时格式操作会清除其内部的所有数据并重新建立一个新的文件系统。需要以 hdfs 用户的身份在 master 节点执行如下命令。</p>

<pre><code class="language-bash">[hdfs@master~]$ hdfs namenode –format
</code></pre>

<h1 id="启动hadoop集群">启动hadoop集群</h1>

<p>启动 Hadoop-YARN 集群的方法有两种：一是在各节点分别启动需要启动的服务，二是在master 节点启动整个集群。</p>

<h2 id="分别启动">分别启动</h2>

<p>master 节点需要启动 HDFS 的 NameNode 服务，以及 YARN 的 ResourceManager 服务。根据我们前述的配置，启动 hdfs 的相关服务需要以 hdfs 用户的身份进行，而启动 yarn 相关的服务需要 yarn 用户的身份进行。</p>

<pre><code class="language-bash">[root@master~]# su - hdfs -c 'hadoop-daemon.sh start namenode'
[root@master~]#su - yarn -c 'yarn-daemon.sh start resourcemanager'
</code></pre>

<p>各 slave 节点需要启动 HDFS 的 DataNode 服务，以及 YARN 的 NodeManager 服务。</p>

<pre><code class="language-bash">[root@master~]# su - hdfs -c 'hadoop-daemon.sh start datanode'
[root@master~]#su - yarn -c 'yarn-daemon.sh start nodemanager'
</code></pre>

<h2 id="在-master-节点控制整个集群">在 master 节点控制整个集群</h2>

<p>集群规模较大时，分别启动各节点的各服务过于繁琐和低效，为此，hadoop 专门提供了start-dfs.sh 和 stop-dfs.sh 来启动及停止整个 hdfs 集群，以及 start-yarn.sh 和 stop-yarn.sh 来启动及停止整个 yarn 集群。</p>

<pre><code class="language-bash">[root@master~]# su - hdfs -c 'start-dfs.sh'
[root@master~]# su - yarn -c 'start-yarn.sh'
</code></pre>

<p>较早版本的 hadoop 会提供 start-all.sh 和 stop-all.sh 脚本来统一控制 hdfs 和 mapreduce，但hadoop 2.0 及之后的版本不建议再使用此种方式。</p>

<h1 id="验证">验证</h1>

<p>集群启动完成后，可在各节点以 jps 命令等验正各进程是否正常运行，也可以通过 Web UI来检查集群的运行状态。</p>

                        </div>


                        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/2018-04-14-hadoop2-setup/">Hadoop2.x 伪分布式安装&amp;部署</a></li>
        
        <li><a href="/posts/how-to-install-mysql-from-source-on-centos-6/">CentOS6源码安装MySQL</a></li>
        
        <li><a href="/posts/solve-sbt-update-scala-slow/">解决sbt更新scala速度慢</a></li>
        
        <li><a href="/posts/r%E5%AE%9E%E6%88%98-%E5%86%B3%E7%AD%96%E6%A0%91/">R实战-决策树</a></li>
        
        <li><a href="/posts/r-kmeans/">R实战-Kmeans</a></li>
        
    </ul>
</div>


                        <div class="post-meta meta-tags">
                            
                            <ul class="clearfix">
                                
                                <li><a href="http://shenheng.xyz/tags/hadoop">hadoop</a></li>
                                
                            </ul>
                            
                        </div>
                    
    <div class="generic-box">
            <div class="share-links" style="text-align:center;">
                <a rel="license"  href="http://creativecommons.org/licenses/by-nc-nd/4.0/">
                    <img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">
                </a>
                <br/>
                
                本文章采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可。
                <br />
                如要转载，请注明出处！
            </div>
    </div>


<style>
.generic-box {
    text-align: center;
    border: 1px solid #eee;
    padding: 10px;
     
    margin: 30px;
};
.share-links a {
    border-bottom: none;
}
</style>


                    </article>
                    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "rh02/replies-registry"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
                </div>
            </div>
            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="http://shenheng.xyz">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-17-hadoop-cfg-explain/" title="Hadoop优化笔记|Hadoop2.x 配置文件">Hadoop优化笔记|Hadoop2.x 配置文件</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-13-kubernetes/" title="kubernetes学习笔记|1.10.0 版环境安装与配置（实验）">kubernetes学习笔记|1.10.0 版环境安装与配置（实验）</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-17-update-kubernetes/" title="kubernetes学习笔记|从旧版本升级到 1.12.1">kubernetes学习笔记|从旧版本升级到 1.12.1</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-17-kubeflow/" title="kubernetes学习笔记|利用 Kubeflow 管理 Tensorflow 程序">kubernetes学习笔记|利用 Kubeflow 管理 Tensorflow 程序</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-17-kubernetes/" title="kubernetes学习笔记|增强版 kubeadm 1.12.1 快速安装">kubernetes学习笔记|增强版 kubeadm 1.12.1 快速安装</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-13-elk-7/" title="ELK学习笔记7| Lucence 的搜索语法">ELK学习笔记7| Lucence 的搜索语法</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-13-elk-6/" title="ELK学习笔记6|ElasticSearch基本概念与架构">ELK学习笔记6|ElasticSearch基本概念与架构</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-11-starlight/" title="starlight 介绍">starlight 介绍</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-11-how-to-use-sql-improve-my-work-pipe/" title="管道化 SQL">管道化 SQL</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/2018-12-11-elk-5/" title="ELK学习笔记5|Kibana可视化-数据表、仪表盘">ELK学习笔记5|Kibana可视化-数据表、仪表盘</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">分类</h3>
<ul class="widget-list">
    
    <li>
        <a href="http://shenheng.xyz/categories/2018/">2018(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/beego/">Beego(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/dicision-tree/">Dicision Tree(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/docker/">Docker(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/git/">Git(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/go-%E5%8C%85%E8%AE%B2%E8%A7%A3/">Go 包讲解(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/go-%E5%B9%B6%E5%8F%91/">Go 并发(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/golang/">Golang(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/jenkins/">Jenkins(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/kmeans/">KMeans(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/storm/">Storm(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/zabbix/">Zabbix(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/blog/">blog(4)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/comment/">comment(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/d3/">d3(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/elk/">elk(7)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/golang/">golang(2)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/hadoop/">hadoop(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/hugo/">hugo(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/kubernetes/">kubernetes(5)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/math/">math(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/matrix/">matrix(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/maven/">maven(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/ml/">ml(2)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/pi/">pi(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/sbt/">sbt(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/scala/">scala(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/shortcode/">shortcode(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%8F%AF%E8%A7%86%E5%8C%96/">可视化(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/">安装教程(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87/">工作效率(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%B9%B6%E5%8F%91/">并发(2)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">开源项目(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/">强化学习算法(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E7%AE%97%E6%B3%95/">算法(2)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E8%BF%90%E7%BB%B4/">运维(1)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">标签</h3>
<div class="tagcloud">
    
    <a href="http://shenheng.xyz/tags/decision-tree/">Decision Tree</a>
    
    <a href="http://shenheng.xyz/tags/devops/">DevOps</a>
    
    <a href="http://shenheng.xyz/tags/docker/">Docker</a>
    
    <a href="http://shenheng.xyz/tags/effective/">Effective</a>
    
    <a href="http://shenheng.xyz/tags/git/">Git</a>
    
    <a href="http://shenheng.xyz/tags/golang%E5%B9%B6%E5%8F%91/">Golang并发</a>
    
    <a href="http://shenheng.xyz/tags/jenkins/">Jenkins</a>
    
    <a href="http://shenheng.xyz/tags/kmeans/">Kmeans</a>
    
    <a href="http://shenheng.xyz/tags/zabbix/">Zabbix</a>
    
    <a href="http://shenheng.xyz/tags/blog/">blog</a>
    
    <a href="http://shenheng.xyz/tags/d3/">d3</a>
    
    <a href="http://shenheng.xyz/tags/disqus/">disqus</a>
    
    <a href="http://shenheng.xyz/tags/elastic-search/">elastic search</a>
    
    <a href="http://shenheng.xyz/tags/elk/">elk</a>
    
    <a href="http://shenheng.xyz/tags/gittalk/">gittalk</a>
    
    <a href="http://shenheng.xyz/tags/golang/">golang</a>
    
    <a href="http://shenheng.xyz/tags/hadoop/">hadoop</a>
    
    <a href="http://shenheng.xyz/tags/k8s/">k8s</a>
    
    <a href="http://shenheng.xyz/tags/kibana/">kibana</a>
    
    <a href="http://shenheng.xyz/tags/kubernetes/">kubernetes</a>
    
    <a href="http://shenheng.xyz/tags/linux/">linux</a>
    
    <a href="http://shenheng.xyz/tags/logstash/">logstash</a>
    
    <a href="http://shenheng.xyz/tags/matrix/">matrix</a>
    
    <a href="http://shenheng.xyz/tags/ml/">ml</a>
    
    <a href="http://shenheng.xyz/tags/pi/">pi</a>
    
    <a href="http://shenheng.xyz/tags/sbt/">sbt</a>
    
    <a href="http://shenheng.xyz/tags/scala/">scala</a>
    
    <a href="http://shenheng.xyz/tags/shortcode/">shortcode</a>
    
    <a href="http://shenheng.xyz/tags/%E4%BC%98%E5%8C%96/">优化</a>
    
    <a href="http://shenheng.xyz/tags/%E5%90%8E%E7%AB%AF/">后端</a>
    
    <a href="http://shenheng.xyz/tags/%E5%AE%B9%E5%99%A8/">容器</a>
    
    <a href="http://shenheng.xyz/tags/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/">容器编排</a>
    
    <a href="http://shenheng.xyz/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">开源项目</a>
    
    <a href="http://shenheng.xyz/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/">强化学习算法</a>
    
    <a href="http://shenheng.xyz/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/">目标检测算法</a>
    
    <a href="http://shenheng.xyz/tags/%E8%BF%90%E7%BB%B4/">运维</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a rel="noreferrer noopener nofollow" href="https://lzzrpi.xin/" title="一个程序员">一个程序员</a>
        </li>
        
        <li>
            <a rel="noreferrer noopener nofollow" href="https://www.shenhengheng.xyz/" title="申恒恒的博客">申恒恒的博客</a>
        </li>
        
        <li>
            <a rel="noreferrer noopener nofollow" href="https://shenheng.readailib.com/" title="毕业设计project网站">Project</a>
        </li>
        
        <li>
            <a rel="noreferrer noopener nofollow" href="https://dir.readailib.com/" title="Directory Lister">Directory Lister</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="http://shenheng.xyz/index.xml">文章 RSS</a></li>
        </ul>
    </section>

    <section class="widget">
        
<section class="widget">
    
    <h3 class="widget-title">我的位置</h3>
    <ul class="widget-list">
            
            <li>
                <div id="allmap">
                        
                        <script  type="text/javascript" src="http://api.map.baidu.com/api?v=1.5&ak=AtWkt6iR9uyuODelXUqfXRth"></script>
                        <script type="text/javascript">
                            
                            var map = new BMap.Map("allmap");
                            var point = new BMap.Point("117.9439850000", "28.4572810000");
                            var marker = new BMap.Marker(point);  
                            map.addOverlay(marker);              
                            map.centerAndZoom(point, 15);
                            var opts = {
                                width : 50,     
                                height: 50,     
                            }
                            var infoWindow = new BMap.InfoWindow("地址：上饶市信州区广信大厦A座3楼", opts);  
                            marker.addEventListener("click", function(){          
                                map.openInfoWindow(infoWindow,point); 
                            });
                        </script>        
                </div> 
                            
            </li>
            
        
    

    </ul>
</section>

    </section>
</div>


        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2018 <a href="http://shenheng.xyz">申恒恒的博客 By 申恒恒</a>.
        Powered by <a rel="nofollow noreferer noopener" href="https://gohugo.io" target="_blank">Hugo</a>.
        <a href="http://www.flysnow.org/" target="_blank">Theme</a> based on <a href="https://github.com/rh02/maupassant-hugo" target="_blank">maupassant</a>.
        
    </div>
</footer>


    <script type="text/javascript" src="/js/prism.js" async="true"></script>
    <script type="text/javascript" src="/js/app.js" defer></script>

    <script type="text/javascript">
    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true
        }
    };
    </script>
    <script  type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>



<script type="text/javascript" src="/js/busuanzi.pure.mini.js" async></script>




</body>
</html>
