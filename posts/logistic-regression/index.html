<!doctype html>
<html lang="zh-CN">
<head>

    
      

    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.51" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>逻辑回归 | Gopher&#39;s Blog</title>
    <meta property="og:title" content="逻辑回归 - Gopher&#39;s Blog">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content="2017-12-21T00:00:00&#43;08:00">
        
        
    <meta property="article:modified_time" content="2017-12-21T00:00:00&#43;08:00">
        
    <meta name="Keywords" content="golang,go语言,go语言笔记,申恒恒,java,android,大数据,Hadoop,Spark,Storm,Streaming,强化学习,计算机视觉,机器学习,深度学习,容器技术,kubernetes,Docker,博客,项目管理,python,软件架构,公众号,小程序">
    <meta name="description" content="逻辑回归">
        <meta name="author" content="Heng-Heng Shen">
        
    <meta property="og:url" content="http://shenheng.xyz/posts/logistic-regression/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href="/css/normalize.css">
    
        <link rel="stylesheet" href="/css/prism.css">
    
    <link rel="stylesheet" href="/css/style.css">
    <script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

    

    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [ ['$','$'] ],
                processEscapes: true
            }
        };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>


    
    
        <link rel="stylesheet" href="/css/douban.css">
    
        <link rel="stylesheet" href="/css/other.css">
    
</head>

<body>
<header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="http://shenheng.xyz">
                        Gopher&#39;s Blog
                    </a>
                
                <p class="description">专注于Python、Java、Go语言(golang)、机器学习、深度学习、大数据、云计算、容器技术、软件架构</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="" href="http://shenheng.xyz">首页</a>
                    
                    <a  href="http://shenheng.xyz/learning/" title="笔记">笔记</a>
                    
                    <a  href="http://shenheng.xyz/archives/" title="归档">归档</a>
                    
                    <a  href="http://shenheng.xyz/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>


<div id="body">
    <div class="container">
        <div class="col-group">

            <div class="col-8" id="main">
                <div class="res-cons">
                    <article class="post">
                        <header>
                            <h1 class="post-title">逻辑回归</h1>
                        </header>
                        <date class="post-meta meta-date">
                            2017年12月21日
                        </date>
                        
                        <div class="post-meta meta-category">
                            |
                            
                                <a href="http://shenheng.xyz/categories/ml">ml</a>
                            
                        </div>
                        
                        
                        <div class="post-meta">
                            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span> 阅读</span></span>
                        </div>
                        
                        <div class="post-content">
                            

<p>\noindent 该笔记是来自 Andrew Ng 的 Machine Learning 课程的第三周:<strong>逻辑回归</strong>的课堂记录，逻辑回归是机器学习分类算法的地一个算法，涵盖信息论的相关内容.主要讲解了以下几个内容:
\begin{itemize}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
- 分类算法的应用
- 二元分类问题
- 边界函数
- 代价函数
- 梯度下降算法
\end{itemize}</p>

<h1 id="分类算法的应用">分类算法的应用</h1>

<p>分类的场景在现实社会中无处不在，比如</p>

<ul>
<li>Email:垃圾邮件分类</li>
<li>金融交易是否存在欺诈</li>
<li>肿瘤是恶性/良性</li>
</ul>

<p>分类问题和回归问题一样，只是现在要预测的值只占一小部分离散值。现在，将重点讨论<strong>二分类</strong>问题，其中$Y$只能接受两个值，<strong>0和1</strong>。（也可以推广到多个类），例如，如果我们试图为电子邮件构建一个垃圾邮件分类器，那么$X^{(i)}$可能是一封电子邮件的一些特征，如果它是一封垃圾邮件，$y$是1，否则为0。因此，$Y \in {0,1}$。0也被称为否定类，1是正类，它们有时也用符号<strong>“-”</strong>和<strong>“+”</strong>表示。</p>

<h1 id="二分类问题">二分类问题</h1>

<p>医疗诊断是机器学习在医学方面其中的一个应用，本小节主要借助乳腺癌诊断这个例子引出.给出一组数据，其中数据特征为肿瘤的大小，标记$y$是0或者1， 其中0表示恶性，1表示良性，将这些样本数据做图如下：</p>

<p>\begin{figure}[htbp]
\begin{center}
  \includegraphics[width=0.7\textwidth]{tumor_logistic.png}
  \caption{乳腺癌数据}\label{figure:tumor_logistic}
\end{center}
\end{figure}
<center>
<img src="http://olrs8j04a.bkt.clouddn.com/17-12-21/24665725.jpg" alt="" />
</center></p>

<p>我们可以尝试使用线性回归加上一个合适的\textbf{“阈值”}来实现分类问题，如图\ref{figure:tumor<em>logistic}所示，$h</em>{\theta}(x) = \theta^{T}x$，则基于阈值0.5的分类器算法如下：
\begin{align<em>}
&amp; h<em>\theta(x) \geq 0.5 \rightarrow y = 1 <br />
&amp; h</em>\theta(x) &lt; 0.5 \rightarrow y = 0
\end{align</em>}</p>

<p>但是这将存在一个很大问题，该算法并不具有鲁棒性，即假设我们有观测到了一个非常大的尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中，这样将会我们之前的假说$h$发生很大变化，如图\ref{figure:tumor_logistic}中最右侧的那个点加入到训练集中，将对$h(x)$影响很大，这时将0.5作为阈值来预测肿瘤是否为恶性就不再合适了。虽然很容易构造出模型来，但用原来的线性回归模型解决分类问题的这种方法表现很差。直观地说，也没有任何道理，通过图\ref{figure:tumor<em>logistic}很容易看出，存在$h</em>{\theta}(x)&gt;1$或者$h<em>{\theta}(x)&lt;0$，但，$Y \in {0,1}$。为了解决这个问题，我们改变$h</em>{\theta}(x)$的形式，使得输出变量$0 \leq  h_{\theta}(x) \leq  1$.我们将使用$Sigmoid$来表示假说函数，也叫为逻辑函数，又因为逻辑函数的输入为$\theta^{T}x$，所以我们的模型又叫做<strong>逻辑回归模型</strong>.</p>

<p>逻辑回归模型为：
\begin{align<em>}
&amp; h_\theta (x) = g ( \theta^T x )<br />
&amp; z = \theta^T x <br />
&amp;g(z) = \dfrac{1}{1 + e^{-z}}
\end{align</em>}</p>

<p>$g(z)$函数图像如图\ref{figure:sigmoid}所示.</p>

<p><center>
<img src="http://olrs8j04a.bkt.clouddn.com/17-12-21/53893816.jpg" alt="" />
</center>
\begin{figure}[htbp]
\begin{center}
    \includegraphics[width=0.7\textwidth]{sigmoid.png}
    \caption{Sigmoid函数图像}\label{figure:sigmoid}
\end{center}
\end{figure}</p>

<p><strong>另外</strong> ，对于给定的数据X，根据选择的参数，$h<em>{\theta}(x)$表示$y=1$发生的可能性。即$h</em>{\theta}(x) = {P}(y=1 | x,\theta)$,例如，$h_{\theta}(x)= 0.7$告诉我们$y=1$的概率为$70\%$，那么根据概率基本知识，$y=0$的概率为$30\%$.</p>

<p>基本的概率公式：
\begin{align<em>}
&amp; h_\theta(x) = P(y=1 | x ; \theta) = 1 - P(y=0 | x ; \theta) <br />
&amp; P(y = 0 | x;\theta) + P(y = 1 | x ; \theta) = 1
\end{align</em>}</p>

<h1 id="边界函数">边界函数</h1>

<h2 id="线性决策边界">线性决策边界</h2>

<p>根据图\ref{figure:sigmoid}和上面的公式，有以下结论.
\begin{align<em>}
&amp;z=0, e^{0}=1 \Rightarrow g(z)=<sup>1</sup>&frasl;<sub>2</sub> <br />
&amp; z \to \infty, e^{-\infty} \to 0 \Rightarrow g(z)=1 <br />
&amp;z \to -\infty, e^{\infty}\to \infty \Rightarrow g(z)=0 <br />
&amp; \theta^{T}x \geq 0 \rightarrow h<em>\theta(x) \geq 0.5 \rightarrow y = 1 <br />
&amp; \theta^{T}x &lt; 0 \rightarrow h</em>\theta(x) &lt; 0.5 \rightarrow y = 0
\end{align</em>}</p>

<p>假设有一个模型，模型表示如下</p>

<p>\begin{align<em>}
&amp; \theta =
\begin{bmatrix}
-3 <br />
1 <br />
1 \end{bmatrix}<br />
&amp; y = 1 \; if \; -3 + 1 x_1 + 1 x_2 \geq 0<br />
&amp; y = 1 \; if \; x_1 + x_2 \geq 3
\end{align</em>}</p>

<p>画出边界，如下图\ref{figure:example}所示.
\begin{figure}[htbp]
\begin{center}
    \includegraphics[width=0.5\textwidth]{example_log.png}
    \caption{线性决策边界}\label{figure:example}
\end{center}
\end{figure}
<center>
<img src="http://olrs8j04a.bkt.clouddn.com/17-12-21/40568449.jpg" alt="" />
</center></p>

<h2 id="非线性决策边界">非线性决策边界</h2>

<p>往往在实际的数据中，数据往往是线性不可分的！所以在此基础之上，引申出非线性决策边界的概念。如图所示，这个边界是一个圆$z = \theta_0 + \theta_1 x_1^2 +\theta_2 x_2^2$或者一个其他的形状将$y = 0$的区域和$y = 1$的区域分开.
\begin{figure}[htbp]
\begin{center}
    \includegraphics[width=0.5\textwidth]{unlinear.png}
    \caption{非线性决策边界}\label{figure:unlinear}
\end{center}
\end{figure}</p>

<p><center>
<img src="http://olrs8j04a.bkt.clouddn.com/17-12-21/68833588.jpg" alt="" />
</center></p>

<p>图\ref{figure:unlinear}，模型描述为：
\begin{align<em>}
h<em>{\theta}(x) &amp;= g(\theta</em>{0} + \theta<em>{1}x</em>{1} + \theta<em>{2}x</em>{2} + \theta<em>{3}x</em>{1}^2 + \theta<em>{4}x</em>{2}^2)<br />
h<em>{\theta}(x) &amp;= g(-1 + 0 x</em>{1} + 0 x<em>{2} + 1 x</em>{1}^2 + 1 x<em>{2}^2)<br />
y &amp;= 1 \; if  \; 1 x</em>{1}^2 + 1 x_{2}^2 \geq 1
\end{align</em>}</p>

<p>我们也可以使用比较复杂的模型来适应非常复杂形状的边界.$h_{\theta}(x) = g(\theta_0 + \theta_1 x_1 +\theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_2^2  + \theta_5 x_1x_2 +&hellip;)$</p>

<h1 id="代价函数">代价函数</h1>

<p>在定义逻辑回归模型的代价函数中，我们不能使用线性回归模型定义的成本函数，因为$logistic$函数会导致$y$出现震荡，从而出现许多局部的最优解，此时定义的代价函数不是一个凸函数。</p>

<p>逻辑回归模型的代价函数为
\begin{align<em>}
 J(\theta) &amp;= \dfrac{1}{m} \sum<em>{i=1}^m \mathrm{Cost}(h</em>\theta(x^{(i)}),y^{(i)})
\end{align</em>}
$$
\left{
 \begin{aligned}
 \mathrm{Cost}(h<em>\theta(x),y) &amp;= -\log(h</em>\theta(x)) \; &amp; \text{if y = 1} <br />
 \mathrm{Cost}(h<em>\theta(x),y) &amp;= -\log(1-h</em>\theta(x)) \; &amp; \text{if y = 0}
  \end{aligned}
\right.$$</p>

<p>当$y=1$和$y=0$时，分别画出 $J(\theta) = \mathrm{Cost}(h_{\theta}(x), y)$的图像，如图\ref{figure:y}</p>

<p>\begin{figure}[htbp]
\centering                                                          %居中
\subfigure[当y=1时]{                    %第一张子图
\begin{minipage}{7cm}
\centering                                                          %子图居中
\includegraphics[scale=0.75]{y1.png}               %以pic.jpg的0.5倍大小输出
\end{minipage}}
\subfigure[当y=0时]{                    %第二张子图
\begin{minipage}{7cm}
\centering                                                          %子图居中
\includegraphics[scale=0.65]{y0.png}                %以pic.jpg的0.5倍大小输出
\end{minipage}}
\caption{$J(\theta)$ vs $h_{\theta}$} %                         %大图名称
\label{figure:y}                                                        %图片引用标记
\end{figure}
<center>
<img src="http://olrs8j04a.bkt.clouddn.com/17-12-21/7436806.jpg" alt="" />
</center></p>

<p>$\mathrm{Cost}(h<em>{\theta}(x),y)$的特点为：
\begin{align*}
&amp; \mathrm{Cost}(h</em>\theta(x),y) = 0 \text{ if } h<em>\theta(x) = y <br />
 &amp; \mathrm{Cost}(h</em>\theta(x),y) \rightarrow \infty \text{ if } y = 0 \; \mathrm{and} \; h<em>\theta(x) \rightarrow 1 <br />
&amp; \mathrm{Cost}(h</em>\theta(x),y) \rightarrow \infty \text{ if } y = 1 \; \mathrm{and} \; h_\theta(x) \rightarrow 0
\end{align*}</p>

<p><strong>公式反映了一个事实：</strong>
如果$h_{\theta}  = 0$，即$\mathrm{P}(y=1 | \theta,x)=0$，但是$\mathrm{y}=1$，则我们将会以一个很大的代价（$\infty$）惩罚学习算法！</p>

<p><strong>上面的话简单点:</strong> 你预测对了，没事！（$\mathrm{OK} \rightarrow \mathrm{Cost} = 0$），但是你如果预测错了，抱歉，狠狠教训一顿！（$\mathrm{Sorry}, \mathrm{Cost} \rightarrow \infty$），其实这是<strong>信息论中熵的应用，信息增益</strong>！</p>

<p>这样写过之后，就保证了代价函数是凸函数！</p>

<h1 id="简化代价函数形式和梯度下降算法">简化代价函数形式和梯度下降算法</h1>

<p>我们可以将
$$ \mathrm{Cost}(h<em>\theta(x),y) =
\left{
 \begin{aligned}
 &amp; -\log(h</em>\theta(x)) \; &amp; \text{if y = 1} <br />
 &amp; -\log(1-h_\theta(x)) \; &amp; \text{if y = 0}
  \end{aligned}
\right.$$</p>

<p>简化为
$$\mathrm{Cost}(h<em>\theta(x),y) = - y \; \log(h</em>\theta(x)) - (1 - y) \log(1 - h_\theta(x))$$</p>

<p>代入代价函数得到：
\begin{align<em>}
J(\theta) &amp;= - \frac{1}{m} \displaystyle \sum<em>{i=1}^m \mathrm{Cost}(h</em>{\theta}(x^{(i)}) - y^{(i)}) <br />
          &amp;= - \frac{1}{m} \displaystyle \sum<em>{i=1}^m [y^{(i)}\log (h</em>\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]
\end{align</em>}</p>

<p>向量化之后：</p>

<p>\begin{align<em>}
&amp; h = g(X\theta)<br />
&amp; J(\theta) = \frac{1}{m} \cdot \left(-y^{T}\log(h)-(1-y)^{T}\log(1-h)\right)
\end{align</em>}
在得到这样的一个代价函数之后，就可以使用梯度下降算法求出使得代价函数最小的参数$\theta$.</p>

<p>梯度下降算法框架如下：
\begin{align<em>}
&amp; Repeat \; \lbrace <br />
&amp; \; \theta_j := \theta_j - \alpha \dfrac{\partial}{\partial \theta_j}J(\theta) <br />
 &amp; \rbrace
\end{align</em>}</p>

<p>将$J(\theta)$代入得</p>

<p>\begin{align<em>} &amp; Repeat \; \lbrace <br />
&amp; \; \theta_j := \theta<em>j - \frac{\alpha}{m} \sum</em>{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} <br />
&amp; \rbrace
 \end{align</em>}</p>

<p>向量化：$$\theta := \theta - \frac{\alpha}{m} X^{T} (g(X \theta ) - \vec{y})$$</p>

<p><strong>注意：</strong> 表面上看起来和线性回归的梯度下降一样，但是这里的$h_{\theta}(x)=g(\theta^{T}x)$与线性回归不同，所以实际上是不一样的。另外在运行梯度下降算法之前，进行特征缩放是非常必要的。</p>

<h1 id="高级优化">高级优化</h1>

<p>“共轭梯度”、“BFGS”-局部优化法、和“L-BFGS”-有限内存局部优化，使用更成熟，更快的方法来优化$\theta$，它们可以用来代替梯度下降。不建议自己编写这些复杂的算法，而是使用库，因为它们已经经过测试并高度优化。Octave提供它们！
\begin{align<em>}
&amp;\mathrm{Given} \; \theta<br />
&amp; \rightarrow J(\theta) <br />
&amp; \rightarrow \frac{\partial}{\partial<em>{\theta</em>{j}}}J(\theta) \;  \mathrm{for} \;{j} = 0,1,2,3,&hellip;
\end{align</em>}</p>

<p>\lstset{language=Matlab}</p>

<p>代码实现：</p>

<p>\begin{lstlisting}
function [jVal, gradient] = costFunction(theta)
  jVal = [&hellip;code to compute J(theta)&hellip;];
  gradient = [&hellip;code to compute derivative of J(theta)&hellip;];
end
\end{lstlisting}</p>

<p><center>
<img src="http://olrs8j04a.bkt.clouddn.com/17-12-21/86473859.jpg" alt="" />
</center></p>

                        </div>

                        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/posts/multi-variable-linear-regression/">多变量线性回归</a></li>
        
        <li><a href="/posts/single-variable-linear-regression/">单变量线性回归</a></li>
        
        <li><a href="/posts/overfitting/">过拟合和正则化</a></li>
        
        <li><a href="/posts/polynomial-regression/">多项式回归</a></li>
        
        <li><a href="/posts/bayesian-learning/">朴素贝叶斯算法</a></li>
        
    </ul>
</div>


                        <div class="post-meta meta-tags">
                            
                            <ul class="clearfix">
                                
                                <li><a href="http://shenheng.xyz/tags/ml">ml</a></li>
                                
                            </ul>
                            
                        </div>
                    </article>
                    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "rh02/replies-registry"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
                </div>
            </div>
            <div id="secondary">
    <section class="widget">
        <form id="search" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="http://shenheng.xyz">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="http://shenheng.xyz/posts/how-to-install-mysql-from-source-on-centos-6/" title="CentOS6源码安装MySQL">CentOS6源码安装MySQL</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/scala-cheatsheet/" title="Scala CheatSheet">Scala CheatSheet</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/scala-learning-resources/" title="Scala Learning Resources">Scala Learning Resources</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/scala-style/" title="Scala Style Guide">Scala Style Guide</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/distributed-programming-in-java-week3-notes/" title="分布式编程第三周课堂笔记">分布式编程第三周课堂笔记</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/solve-sbt-update-scala-slow/" title="解决sbt更新scala速度慢">解决sbt更新scala速度慢</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/distributed-programming-in-java-week1-notes/" title="分布式编程第一周课堂笔记">分布式编程第一周课堂笔记</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/distributed-programming-in-java-week2-notes/" title="分布式编程第二周课堂笔记">分布式编程第二周课堂笔记</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/r-kmeans/" title="R实战-Kmeans">R实战-Kmeans</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/posts/r%E5%AE%9E%E6%88%98-%E5%86%B3%E7%AD%96%E6%A0%91/" title="R实战-决策树">R实战-决策树</a>
    </li>
    
</ul>
    </section>

    
<section class="widget">
    <h3 class="widget-title" style="color:red">福利派送</h3>
    <ul class="widget-list">
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?userCode=jdg9oj97" class="ads" title="领取￥1888阿里云产品通用代金券" target="_blank" style="color:red">
                
                    领取￥1888阿里云产品通用代金券
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/act/vmpt/aliyun-group/home.html?userCode=jdg9oj97" class="ads" title="领取￥1888阿里云产品通用代金券" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB17qJhXpzqK1RjSZFvXXcB7VXa-200-126.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/act/enterprise-discount.html?userCode=jdg9oj97" class="ads" title="领取￥1888阿里云产品通用代金券" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1aDXhXpzqK1RjSZFvXXcB7VXa-259-194.jpg">
                
            </a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">分类</h3>
<ul class="widget-list">
    
    <li>
        <a href="http://shenheng.xyz/categories/2018/">2018(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/dicision-tree/">Dicision Tree(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/kmeans/">KMeans(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/pcdp/">PCDP(2)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/blog/">blog(7)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/comment/">comment(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/dpcp/">dpcp(2)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/hmm/">hmm(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/java/">java(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/mail-server/">mail server(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/math/">math(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/matrix/">matrix(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/maven/">maven(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/ml/">ml(9)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/pi/">pi(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/rmarkdown/">rmarkdown(3)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/rpi/">rpi(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/sbt/">sbt(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/scala/">scala(4)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/template/">template(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/welcome/">welcome(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%96%E7%A8%8B/">分布式编程(1)</a>
    </li>
    
    <li>
        <a href="http://shenheng.xyz/categories/%E8%BF%90%E7%BB%B4/">运维(1)</a>
    </li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title">标签</h3>
<div class="tagcloud">
    
    <a href="http://shenheng.xyz/tags/decision-tree/">Decision Tree</a>
    
    <a href="http://shenheng.xyz/tags/kmeans/">Kmeans</a>
    
    <a href="http://shenheng.xyz/tags/pcdp/">PCDP</a>
    
    <a href="http://shenheng.xyz/tags/blog/">blog</a>
    
    <a href="http://shenheng.xyz/tags/cheatsheet/">cheatsheet</a>
    
    <a href="http://shenheng.xyz/tags/disqus/">disqus</a>
    
    <a href="http://shenheng.xyz/tags/dpcp/">dpcp</a>
    
    <a href="http://shenheng.xyz/tags/gitalk/">gitalk</a>
    
    <a href="http://shenheng.xyz/tags/gittalk/">gittalk</a>
    
    <a href="http://shenheng.xyz/tags/hmm/">hmm</a>
    
    <a href="http://shenheng.xyz/tags/linux/">linux</a>
    
    <a href="http://shenheng.xyz/tags/mailserver/">mailserver</a>
    
    <a href="http://shenheng.xyz/tags/matrix/">matrix</a>
    
    <a href="http://shenheng.xyz/tags/ml/">ml</a>
    
    <a href="http://shenheng.xyz/tags/pi/">pi</a>
    
    <a href="http://shenheng.xyz/tags/rmarkdown/">rmarkdown</a>
    
    <a href="http://shenheng.xyz/tags/rpi/">rpi</a>
    
    <a href="http://shenheng.xyz/tags/sbt/">sbt</a>
    
    <a href="http://shenheng.xyz/tags/scala/">scala</a>
    
    <a href="http://shenheng.xyz/tags/scala-style/">scala style</a>
    
    <a href="http://shenheng.xyz/tags/%E8%BF%90%E7%BB%B4/">运维</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a rel="noreferrer noopener nofollow" href="http://yuedu.baidu.com/ebook/14a722970740be1e640e9a3e" title="Android Gradle权威指南">Android Gradle权威指南</a>
        </li>
        
        <li>
            <a rel="noreferrer noopener nofollow" href="http://mirrors.flysnow.org/" title="常用开发工具CDN镜像">常用开发工具CDN镜像</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="http://shenheng.xyz/index.xml">文章 RSS</a></li>
        </ul>
    </section>

    
</div>
        </div>
    </div>
</div>
<footer id="footer">
    <div class="container">
        &copy; 2018 <a href="http://shenheng.xyz">Gopher&#39;s Blog By 申恒恒</a>.
        Powered by <a rel="nofollow noreferer noopener" href="https://gohugo.io" target="_blank">Hugo</a>.
        <a href="http://www.flysnow.org/" target="_blank">Theme</a> based on <a href="https://github.com/rujews/maupassant-hugo" target="_blank">maupassant</a>.
        
    </div>
</footer>


    <script type="text/javascript" src="/js/prism.js" async="true"></script>
    <script type="text/javascript">
    window.MathJax = {
        tex2jax: {
            inlineMath: [ ['$','$'] ],
            processEscapes: true
        }
    };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src="/js/totop.js?v=0.0.0" async=""></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', '48ac64a24eebc5cb273da3d6a926069b', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



<script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




  <script src="/js/douban.js"></script>

</body>
</html>
